services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    environment:
      ZOOKEEPER_CLIENT_PORT: "2181"
      ZOOKEEPER_TICK_TIME: "2000"
    ports:
      - "2181:2181"
    volumes:
      - /runtime/shared/system-design-lab/top_k_user_aggregation/zookeeper/data:/var/lib/zookeeper/data
      - /runtime/shared/system-design-lab/top_k_user_aggregation/zookeeper/log:/var/lib/zookeeper/log

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: "1"
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
    volumes:
      - /runtime/shared/system-design-lab/top_k_user_aggregation/kafka:/var/lib/kafka/data

  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: "topk"
      POSTGRES_PASSWORD: "topk"
      POSTGRES_DB: "topk"
    ports:
      - "5432:5432"
    volumes:
      - /runtime/shared/system-design-lab/top_k_user_aggregation/postgres:/var/lib/postgresql/data
      - ./schemas/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro

  cassandra:
    image: cassandra:4.1
    environment:
      CASSANDRA_CLUSTER_NAME: "topk-cluster"
      CASSANDRA_NUM_TOKENS: "16"
      MAX_HEAP_SIZE: "1G"
      HEAP_NEWSIZE: "200M"
    ports:
      - "9042:9042"
    volumes:
      - /runtime/shared/system-design-lab/top_k_user_aggregation/cassandra:/var/lib/cassandra

  redis:
    image: redis/redis-stack-server:latest
    ports:
      - "6379:6379"
    volumes:
      - /runtime/shared/system-design-lab/top_k_user_aggregation/redis:/data
    environment:
      - REDIS_ARGS=--appendonly yes

  # NEW: DB-backed scheduler for crawl jobs
  crawl-scheduler:
    build:
      context: ./services/crawl-scheduler
      dockerfile: Dockerfile
    depends_on:
      - postgres
      - redis
    environment:
      POSTGRES_URL: "postgres://topk:topk@postgres:5432/topk?sslmode=disable"
      REDIS_ADDR: "redis:6379"
      POLL_INTERVAL: "10s"
      STUCK_THRESHOLD: "1h"
    restart: unless-stopped

  crawl-worker:
    build:
      context: ./services/crawl-worker
      dockerfile: Dockerfile
    depends_on:
      - redis
      - kafka
      - postgres
    environment:
      REDIS_ADDR: "redis:6379"
      KAFKA_BROKER: "kafka:9092"
      POSTGRES_URL: "postgres://topk:topk@postgres:5432/topk?sslmode=disable"
    restart: unless-stopped

  raw-event-processor:
    build:
      context: ./services/raw-event-processor
      dockerfile: Dockerfile
    depends_on:
      - kafka
      - cassandra
    environment:
      KAFKA_BROKER: "kafka:9092"
      CASSANDRA_HOSTS: "cassandra"
      CONSUMER_GROUP: "raw-event-processor"
    restart: unless-stopped

  aggregator:
    build:
      context: ./services/aggregator
      dockerfile: Dockerfile
    depends_on:
      - kafka
      - cassandra
      - redis
    environment:
      KAFKA_BROKER: "kafka:9092"
      CASSANDRA_HOSTS: "cassandra"
      REDIS_ADDR: "redis:6379"
      CONSUMER_GROUP: "aggregator"
      FLUSH_INTERVAL: "30s"
    restart: unless-stopped

  api-server:
    build:
      context: ./services/api-server
      dockerfile: Dockerfile
    depends_on:
      - cassandra
      - redis
    ports:
      - "8081:8081"
    environment:
      CASSANDRA_HOSTS: "cassandra"
      REDIS_ADDR: "redis:6379"
      PORT: "8081"
      CACHE_TTL: "1h"
    restart: unless-stopped

  # One-off: enqueue a test crawl job (for manual testing only)
  enqueue-test:
    build:
      context: ./services/crawl-worker
      dockerfile: Dockerfile.enqueue-test
    depends_on:
      - redis
    environment:
      REDIS_ADDR: "redis:6379"
    profiles:
      - tools
